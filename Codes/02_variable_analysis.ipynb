{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew,kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import cbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../output_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical,categorical = [],[]\n",
    "for col in df.columns:\n",
    "    if 'int' in str(df[col].dtypes) or 'float' in str(df[col].dtypes):\n",
    "        numerical.append(col)\n",
    "    else:\n",
    "        categorical.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(numerical,open('numerical.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(categorical,open('categorical.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edd(data):\n",
    "    df_desc = data.describe().transpose()\n",
    "    df_desc['Var'] = df_desc.index\n",
    "    df_desc.reset_index(inplace=True)\n",
    "    df_desc.drop('count',axis=1,inplace=True)\n",
    "    df_desc['skewness'] = df_desc['Var'].apply(lambda x: skew(np.array(data.loc[data[x].notnull(),x])))\n",
    "    df_desc['kurtosis'] = df_desc['Var'].apply(lambda x: kurtosis(np.array(data.loc[data[x].notnull(),x]),fisher=False))\n",
    "    df_desc['99%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.99))\n",
    "    df_desc['95%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.95))\n",
    "    df_desc['90%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.90))\n",
    "    df_desc['10%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.1))\n",
    "    df_desc['5%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.05))\n",
    "    df_desc['1%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.01))\n",
    "    df_desc['mean-3sigma'] = df_desc['mean'] - 3*df_desc['std']\n",
    "    df_desc['mean+3sigma'] = df_desc['mean'] + 3*df_desc['std']\n",
    "    df_desc['mean-2sigma'] = df_desc['mean'] - 2*df_desc['std']\n",
    "    df_desc['mean+2sigma'] = df_desc['mean'] + 2*df_desc['std']\n",
    "    df_desc['type']='numeric'\n",
    "    \n",
    "    def is_category(col):\n",
    "        return 'float' not in str(data[col].dtype) and 'int' not in str(data[col].dtype)\n",
    "    \n",
    "    categorical = [col for col in data.columns if is_category(col)]\n",
    "    df_categorical = pd.DataFrame()\n",
    "    df_categorical['Var']=np.array(categorical)\n",
    "    \n",
    "    df_categorical['type']='categorical'\n",
    "    for col in [c for c in df_desc.columns if c not in ['Var','type']]:\n",
    "        df_categorical[col]=np.nan\n",
    "    for col in categorical:\n",
    "        df_var = data[col].value_counts()\n",
    "        df_cat = pd.DataFrame()\n",
    "        df_cat['count']=df_var\n",
    "        df_cat['categories']=df_var.index\n",
    "        df_cat.reset_index(inplace=True)\n",
    "        df_cat.sort_values(by='count',ascending=False,inplace=True)\n",
    "        df_cat.set_index('categories',inplace=True)\n",
    "        index_list = df_cat.index.tolist()\n",
    "        for i,c in enumerate(['mean','min','1%','5%','10%','25%']):\n",
    "            try:\n",
    "                df_categorical.loc[df_categorical['Var']==col,c] = index_list[i]\n",
    "            except:\n",
    "                break\n",
    "        for i,c in enumerate(['50%','75%','90%','95%','99%','max']):\n",
    "            try:\n",
    "                df_categorical.loc[df_categorical['Var']==col,c] = index_list[-(i+1)]\n",
    "            except:\n",
    "                break\n",
    "        del df_var\n",
    "        del df_cat\n",
    "        del index_list\n",
    "    df_categorical = df_categorical[df_desc.columns]\n",
    "    edd = pd.concat([df_desc,df_categorical])\n",
    "    del df_desc\n",
    "    del df_categorical\n",
    "    edd['count'] = edd['Var'].apply(lambda x: data[data[x].notnull()].shape[0])\n",
    "    edd['nmiss'] = data.shape[0]-edd['count']\n",
    "    edd['missing_rate'] = np.array(edd['nmiss']).astype('float')/data.shape[0] * 100\n",
    "    edd['unique'] = edd['Var'].apply(lambda x: len(data[x].value_counts().index.tolist()))\n",
    "    orig_cols = ['mean','min','1%','5%','10%','25%','50%','75%','90%','95%','99%','max']\n",
    "    new_cols = ['mean_or_top1','min_or_top2','p1_or_top3','p5_or_top4','p10_or_top5','p25_or_top6',\n",
    "                'p50_or_bottom6','p75_or_bottom5','p90_or_bottom4','p95_or_bottom3','p99_or_bottom2','max_or_bottom1']\n",
    "    \n",
    "    convert_dict = {}\n",
    "    for i in range(len(orig_cols)):\n",
    "        convert_dict[orig_cols[i]]=new_cols[i]\n",
    "    edd.rename(columns=convert_dict,inplace=True)\n",
    "    edd = edd[['Var','type','count','nmiss','missing_rate','unique','std','skewness','kurtosis','mean-3sigma',\n",
    "               'mean-2sigma','mean_or_top1','min_or_top2','p1_or_top3','p5_or_top4','p10_or_top5','p25_or_top6',\n",
    "               'p50_or_bottom6','p75_or_bottom5','p90_or_bottom4','p95_or_bottom3','p99_or_bottom2','max_or_bottom1'\n",
    "              ,'mean+2sigma','mean+3sigma']]\n",
    "    return edd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd = edd(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../Statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.to_csv('edd_v01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation(col):\n",
    "    if col in numerical:\n",
    "        corr_matrix = df.corr()\n",
    "        return corr_matrix.loc['SalePrice',col]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd['correlation'] = edd['Var'].apply(lambda x: correlation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_dict = {'log':lambda x: np.log(x),'sqr':lambda x: x**2,'sqrt':lambda x: np.sqrt(x),'exp':lambda x:np.exp(x),\n",
    "                 'cube':lambda x: x**3,'cuberoot': lambda x: cbrt(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd['Status'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd['transformed_correlation'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for col in [x for x in numerical if x != 'SalePrice']:\n",
    "    corr_max = np.abs(edd.loc[edd['Var']==col,'correlation'].values)\n",
    "    for t in transform_dict.keys():\n",
    "        df_new = df[[col,'SalePrice']]\n",
    "        df_new.dropna(how='any',axis=0,inplace=True)\n",
    "        try:\n",
    "            df_new[col] = df_new[col].apply(transform_dict[t])\n",
    "            if not (True in np.isinf(np.array(df_new[col]))):\n",
    "                corr_matrix = df_new.corr()\n",
    "                corr = corr_matrix.loc['SalePrice',col]\n",
    "                if np.abs(corr)>corr_max:\n",
    "                    corr_max=np.abs(corr)\n",
    "                    edd.loc[edd['Var']==col,'Status']=t\n",
    "                    edd.loc[edd['Var']==col,'transformed_correlation']=corr\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            50\n",
       "cube        10\n",
       "cuberoot     8\n",
       "sqrt         5\n",
       "sqr          5\n",
       "exp          1\n",
       "log          1\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edd['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.to_csv('edd_v02.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../output_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(x,function):\n",
    "    if x is not None:\n",
    "        return function(x)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical:\n",
    "    if edd.loc[edd['Var']==col,'Status'].values[0] != '':\n",
    "        function = transform_dict[edd.loc[edd['Var']==col,'Status'].values[0]]\n",
    "        df[col] = df[col].apply(lambda x: transform(x,function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('train_v01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
